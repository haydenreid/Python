{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math as m\n",
    "import statistics as s\n",
    "from random import choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in data and finding my row of observations, setting a seed to keep results consistent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(7)\n",
    "mydata = pd.DataFrame(pd.read_csv(\"exam2.csv\", index_col = 0)).loc[hashlib.md5(\"hjr160230\".encode('utf-8')).hexdigest()]\n",
    "x = mydata.copy().values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I will start by estimating the upper and lower bounds of the data. Using bootstrapping, we can generate a variance of the lower and upper bounds which we can use to estimate the true parameters. In this case, I am generating 10000 different bootstrapped samples and saving the sampled minimum values in \"minvec\" and the sampled maximum values in \"maxvec\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "minvec = []\n",
    "maxvec = []\n",
    "\n",
    "for i in range(10000):\n",
    "    sample = np.random.choice(x,200,replace=True)\n",
    "    minvec.append(min(sample))\n",
    "    maxvec.append(max(sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the values previously generated, we can get a variance corresponding to both the upper and lower bound, and subsequently we can get a standard error as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9137276112732381, 0.027392348717382498)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minvec = pd.DataFrame(minvec).values\n",
    "maxvec = pd.DataFrame(maxvec).values\n",
    "minvec.var(),maxvec.var()\n",
    "stderrmin = minvec.std()\n",
    "stderrmax = maxvec.std()\n",
    "stderrmin,stderrmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that the true parameter lies somewhere outside the minimum and maximum values in our data, and we also know that because of the central limit theorem, our minimum and maximum samples follow a normal distribution. To estimate our true lower bound using these two assumptions, we can fit a normal distribution with our lower bound falling on the far right of the curve (at an extreme position, so that the probability of finding the datasets minimum value as the true parameter is less than .0002). Under this distribution, we can say the true mean lies 3.5 standard errors to the left of the lower bound and 3.5 standard errors to the right of the upper bound, calculated below. The final value observed for the true lower bound is -7.233 and the true upper bound is 10.813."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-7.233651507456333, 10.81250419051084)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb = -(3.5*stderrmin)+min(x)\n",
    "ub = (3.5*stderrmax)+max(x)\n",
    "lb,ub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the lower bound and the upper bound are estimated, we can convert our x values to the scaled z values, so they are bounded between 0 and 1. This will normalize our kumaraswamy distribution, and allow us to best estimate our a and b parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = (x - lb)/(ub-lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create order statistics for both the x data (unscaled) and the z data (scaled)\n",
    "z_order = np.array(sorted(z.copy()))\n",
    "x_order = np.array(sorted(x.copy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I am creating a uniform distribution with bounds 0 and 1, of size 200. Using the uniform distribution, I can \n",
    "convert to a kumaraswamy distribution and use this as a test dataset for parameter estimates where they are known\n",
    "ahead of time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "unif = np.random.uniform(low=0.0,high=1.0,size = 200)\n",
    "# setting known parameters to estimate. \n",
    "truea = 2\n",
    "trueb = 3\n",
    "# converting our uniform distribution to kumaraswamy. \n",
    "kumar = (1 - (1 - unif)**(1/trueb))**(1/truea)\n",
    "kumar = sorted(kumar)\n",
    "kumar = np.array(kumar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I am setting up vectors to contain different values for a and b, stepping by .1, and looping to generate errors\n",
    "when comparing my true data to my test data. It should be noted that the test data and the true data being compared are sorted, so the smallest values are compared with similar smaller values, and the errors are squared to account for negative and postive values offsetting each other. The uniform distribution for the tests data changes every time in an \n",
    "effort to simulate the fact that the underlying values are unknown and the \"parent\" uniform values are different.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "avec = np.arange(1.5, 2.5, 0.1)\n",
    "bvec = np.arange(2.5, 3.5, 0.1)\n",
    "outp = []\n",
    "for i in range(5000):\n",
    "    unif2 = np.random.uniform(low=0.0,high=1.0,size = 200)\n",
    "    errvec = 20\n",
    "    outp2 = []\n",
    "    for a in range(len(avec)):\n",
    "        for b in range(len(bvec)):\n",
    "            testkumar = (1 - (1 - unif2)**(1/bvec[b]))**(1/avec[a])\n",
    "            testkumar = sorted(testkumar)\n",
    "            testkumar = np.array(testkumar)\n",
    "            err = ((kumar - testkumar)**2).sum()\n",
    "            if err < errvec:\n",
    "                errvec = err\n",
    "                # for each uniform distribution, we only save the errors if the a and b combination has a smaller error than\n",
    "                # the previous combination. This way, the last estimates in the outp2 variable has the smallest error. \n",
    "                outp2 += [[avec[a],bvec[b],errvec]]\n",
    "    outp += [outp2[-1]]\n",
    "outp = pd.DataFrame(outp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a      2.002439\n",
       "b      3.131707\n",
       "err    0.022583\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outp.columns = ['a','b','err']\n",
    "outp.sort_values(by='err')\n",
    "(outp.loc[outp['err'] <= .025]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After generating errors against 5000 different uniform distributions, we can average the a and b values at which we \n",
    "find errors under a certain threshold. Because we know the true parameters ahead of time, we have quite small errors\n",
    "and can choose a small threshold. I suspect using this method against the true dataset will have a larger error and the thrreshold will have to be larger. Here we estimate a to be ~1.96 and be to be ~3.05. These values are pretty close to the true parameters defined above at 2 and 3, so this method seems to be effective for estimating the parameters of a kumaraswamy distribution. NOTE: despite setting a seed in the program, the random uniform distributions seem to be different every time the loop is run, and the estimates stated above may not be the same as what is output when run a different time. In all of the tests, however, the values still estimate the true parameters closely. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can implement this strategy on the real dataset provided. We are essentially doing the same thing here: creating a random unifrom distribution, converting it to a kumaraswamy distribution using a variety of test values for a and b, and generating an error term between the true data (z_order) and the test data (testkumar). In outp, I am saving the combination of a and b that generates the smallest error. This outp list holds 100 different smallest errors for each random uniform distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "avec = np.arange(1, 10, 0.5)\n",
    "bvec = np.arange(1, 10, 0.5)\n",
    "outp = []\n",
    "outp2 = []\n",
    "for i in range(100):\n",
    "    unif2 = np.random.uniform(low=0.0,high=1.0,size = 200)\n",
    "    errvec = 20\n",
    "    for a in range(len(avec)):\n",
    "        for b in range(len(bvec)):\n",
    "            testkumar = (1 - (1 - unif2)**(1/bvec[b]))**(1/avec[a])\n",
    "            testkumar = sorted(testkumar)\n",
    "            testkumar = np.array(testkumar)\n",
    "            err = ((z_order - testkumar)**2).sum()\n",
    "            if err < errvec:\n",
    "                errvec = err\n",
    "                outp2 += [[avec[a],bvec[b],errvec]]\n",
    "    outp += [outp2[-1]]\n",
    "outp = pd.DataFrame(outp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a bit of formatting, we can take an average of a and b values where the error falls under a certain threshold, here I chose 1.1 (still quite a small squared error) arbitrarily. We see that our estimates put a at ~9 and b at ~2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a      9.231481\n",
       "b      2.064815\n",
       "err    0.994825\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outp.columns = ['a','b','err']\n",
    "outp.sort_values(by='err')\n",
    "(outp.loc[outp['err'] <= 1.1]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing that our a is somewhere around 9 and our b is somewhere around 2, I have tightened the bounds and lowered the step to find a more accurate estimation. Additionally, I have increased the number of random distributions tested against to find more estimated errors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "avec = np.arange(7, 10, 0.1)\n",
    "bvec = np.arange(1, 3, 0.1)\n",
    "outp = []\n",
    "for i in range(2000):\n",
    "    unif2 = np.random.uniform(low=0.0,high=1.0,size = 200)\n",
    "    errvec = 20\n",
    "    outp2 = []\n",
    "    for a in range(len(avec)):\n",
    "        for b in range(len(bvec)):\n",
    "            testkumar = (1 - (1 - unif2)**(1/bvec[b]))**(1/avec[a])\n",
    "            testkumar = sorted(testkumar)\n",
    "            testkumar = np.array(testkumar)\n",
    "            err = ((z_order - testkumar)**2).sum()\n",
    "            if err < errvec:\n",
    "                errvec = err\n",
    "                outp2 += [[avec[a],bvec[b],errvec]]\n",
    "    outp += [outp2[-1]]\n",
    "outp = pd.DataFrame(outp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With smaller steps and more estimates (2000 compared to 100) we can get a more accurate estimate for a and b. Here we see a is estimated at ~9.6 and b is estimated at ~2.2. These are my final estimations for the a and b parameters for the kumaraswamy distribution. NOTE: here again, the distributions are different every time the loop is ran, so different estimates may be seen when running code again. I am still  able to get similar estimates in every trial, so this method should still properly approximate the true parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9.550638977635655, 2.191054313099043)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outp.columns = ['a','b','err']\n",
    "outp.sort_values(by='err')\n",
    "(outp.loc[outp['err'] <= 1.1]).mean()\n",
    "estimates = outp.loc[outp['err'] <= 1.1].mean()\n",
    "a = estimates[0]\n",
    "b = estimates[1]\n",
    "a,b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation\n",
    "Sumit Paul and I decided to share our estimation methods with each other to cross validate our estimates. Below is the estimation method he used on my data set. This process was only for validation, and the method shown above should be taken as my true estimations and thought process on the problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this estimation method, Sumit used the median and mean formulas from the Kumaraswamy wikipedia page to estimate a and b. We are comparing the median of the true dataset to a generated median using a test Kumaraswamy dataset, and testing for different values of a and b. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "zmed = np.median(z)\n",
    "zmean = z.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are validating the similarity between using the np.median (i.e. calculating the median the traditional way, as the center of the data) and the median formula for Kumaraswamy distributions. At each value of a and b, we are getting an average error of .002, meaning that the median values differ only slightly. This means we can use the \"traditional\" median of our dataset to estimate a and b by comparing it with the Kumaraswamy median and minimizing error. I also have created upper and lower bounds on the error of the median to account for the differences in calculation between Kumaraswamy median and traditional median. When estimating error  on the true dataset, I will look for error values between those upper and lower bounds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0021790696636603147"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 200\n",
    "medianerr = []\n",
    "\n",
    "for a in range(1,100):\n",
    "    for b in range(1,100):\n",
    "        x1 = np.random.uniform(size=(n,))\n",
    "        kumar = (1-((1-x1)**(1/b)))**(1/a)\n",
    "        kumarmed = (1-(2**(-1/b)))**(1/a)\n",
    "        medianerr.append(abs(np.median(kumar) - kumarmed))\n",
    "avgerrmed = np.mean(medianerr)\n",
    "avgerrmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdevmed = s.stdev(medianerr)\n",
    "uppermed = avgerrmed + 1.645*stdevmed\n",
    "lowermed = avgerrmed - 1.645*stdevmed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here again, we are validating the similarity between the traditional calculation of the mean against the Kumaraswamy calculation of the mean. Similarly to the median, we see an average error of .001, indicating that the means differ only slightly. Upper and lower bounds are generated here as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0018250516339257785"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meanerr = []\n",
    "\n",
    "for a in range(1,100):\n",
    "    for b in range(1,100):\n",
    "        x1 = np.random.uniform(size=(n,))\n",
    "        kumar = (1-((1-x1)**(1/b)))**(1/a)\n",
    "        kumarmean = (b*(m.gamma(1+(1/a)))*m.gamma(b))/(m.gamma(1+(1/a)+b))\n",
    "        meanerr.append(abs(np.mean(kumar) - kumarmean))\n",
    "avgerrmean = np.mean(meanerr)\n",
    "avgerrmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdevmean = s.stdev(meanerr)\n",
    "uppermean = avgerrmean + 1.645*stdevmean\n",
    "lowermean = avgerrmean - 1.645*stdevmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "avec = np.arange(1, 10, 0.1)\n",
    "bvec = np.arange(1, 10, 0.1)\n",
    "errtest = 20\n",
    "outp2 = []\n",
    "\n",
    "for a in range(len(avec)):\n",
    "    for b in range(len(bvec)):\n",
    "        testmed = (1-(2**(-1/bvec[b])))**(1/avec[a])\n",
    "        err = abs(zmed - testmed)\n",
    "        if err > lowermed and err < uppermed:\n",
    "            errtest = err\n",
    "            outp2 += [[avec[a],bvec[b],err]]\n",
    "outp2 = pd.DataFrame(outp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a      7.846053\n",
       "b      2.087500\n",
       "err    0.003414\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outp2.columns = ['a','b','err']\n",
    "outp2.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "avec = np.arange(1, 10, 0.1)\n",
    "bvec = np.arange(1, 10, 0.1)\n",
    "errtest = 20\n",
    "outp3 = []\n",
    "\n",
    "for a in range(len(avec)):\n",
    "    for b in range(len(bvec)):\n",
    "        testmean = (bvec[b]*(m.gamma(1+(1/avec[a])))*m.gamma(bvec[b]))/(m.gamma(1+(1/avec[a])+bvec[b]))\n",
    "        err = abs(zmean - testmean)\n",
    "        if err > lowermean and err < uppermean:\n",
    "            errtest = err\n",
    "            outp3 += [[avec[a],bvec[b],err]]\n",
    "outp3 = pd.DataFrame(outp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a      8.210204\n",
       "b      1.744898\n",
       "err    0.002711\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outp3.columns = ['a','b','err']\n",
    "outp3.mean(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize this process, I wound up getting an estimated a value of 7.85 and b value of 2.08 for the median estimation and an a value of 8.2 and b value of 1.74 for the mean estimation. Comparing these values to my original approach, we can further validate that the true b parameter is in fact around 2. In contrast, the a value has a lot of variation between the 3 methods. Again, this method was only for cross validation and my original approach should be treated as my best estimate for this assignment. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
